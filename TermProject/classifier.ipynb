{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import string\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk.sentiment.util\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReviewNames(posDir, negDir):\n",
    "    positive = glob.glob(posDir)\n",
    "    negative = glob.glob(negDir)\n",
    "#     print(positive)\n",
    "#     print(negative)\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads dataset in a way that will work with scikit\n",
    "def getPosNegReviews(directory):\n",
    "    positive, negative = loadReviewNames(directory + '/pos/*',directory + '/neg/*')\n",
    "    random.shuffle(positive)\n",
    "    boundaryTrain = math.floor(0.8 * len(positive))\n",
    "    trainPos = positive[:boundaryTrain]\n",
    "    random.shuffle(negative)\n",
    "    trainNeg = negative[:boundaryTrain]\n",
    "    \n",
    "    testPos = positive[boundaryTrain:]\n",
    "    testNeg = negative[boundaryTrain:]\n",
    "    return trainPos,trainNeg,testPos,testNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDir(name):\n",
    "    # Loads the files in the folder and returns a list of lists of words from the text in each file\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    data = []\n",
    "    count = 0\n",
    "    for f in tqdm(listdir(name)):\n",
    "        fullname = name+f\n",
    "        text = []\n",
    "        with open(fullname, 'r') as f:\n",
    "            for line in f:\n",
    "                text += myTokenize(line)\n",
    "        data.append(text)\n",
    "        count = count + 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads dataset in a way that will work with my unigram Naive bayes implementation\n",
    "def loadDatasetNB(directory):\n",
    "    positive = loadDir(directory + '/pos/')\n",
    "    negative = loadDir(directory + '/neg/')\n",
    "#     print(\"tokenize in load\")\n",
    "#     print(positive)\n",
    "#     for review in positive:\n",
    "#         review = myTokenize(review)\n",
    "#     for review in negative:\n",
    "#         review = myTokenize(review)\n",
    "        \n",
    "    random.shuffle(positive)\n",
    "    boundaryTrain = math.floor(0.8 * len(positive))\n",
    "    trainPos = positive[:boundaryTrain]\n",
    "    random.shuffle(negative)\n",
    "    trainNeg = negative[:boundaryTrain]\n",
    "    combinedTrain = trainPos + trainNeg\n",
    "    length = len(trainPos) + len(trainNeg)\n",
    "    labelsTrain = len(trainNeg) * [1] + len(trainNeg) * [0]\n",
    "    labelsTrain = np.array(labelsTrain)\n",
    "\n",
    "    testPos = positive[boundaryTrain:]\n",
    "    testNeg = negative[boundaryTrain:]\n",
    "    combinedTest = testPos + testNeg\n",
    "    labelsTest = len(testPos) * [1] + len(testNeg) * [0]\n",
    "    labelsTest = np.array(labelsTest)\n",
    "    return combinedTrain, labelsTrain, combinedTest, labelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for unigram Naive bayes implementation\n",
    "def bagOfWordsNB(train_set, train_labels):\n",
    "    mydict = {}\n",
    "    posV = 0\n",
    "    negV = 0\n",
    "    totalposwords = 0\n",
    "    totalnegwords = 0\n",
    "\n",
    "#   start = time.process_time()\n",
    "\n",
    "    #create bag of words and number of occurences\n",
    "    count = 0\n",
    "    for x in train_set:\n",
    "        rating = train_labels[count]\n",
    "        count += 1\n",
    "        if(rating):\n",
    "            for y in x:\n",
    "                if y not in mydict:\n",
    "                    mydict[y] = [1,0] #default [1 pos, 0 neg]\n",
    "                    posV += 1\n",
    "                    totalposwords += 1\n",
    "                else:\n",
    "                    if mydict[y][0] == 0:\n",
    "                        posV += 1\n",
    "                    mydict[y][0] += 1\n",
    "                    totalposwords += 1\n",
    "        else:\n",
    "            for y in x:\n",
    "                if y not in mydict:\n",
    "                    mydict[y] = [0,1] #default [0 pos, 1 neg]\n",
    "                    negV += 1\n",
    "                    totalnegwords += 1\n",
    "                else:\n",
    "                    if mydict[y][1] == 0:\n",
    "                        negV += 1\n",
    "                    mydict[y][1] += 1\n",
    "                    totalnegwords += 1\n",
    "#     print(\"review count is: \", count)\n",
    "#     print(\"posV\", posV)\n",
    "#     print(\"negV\", negV)\n",
    "#     print(\"total word count is:\", totalposwords + totalnegwords)\n",
    "    BOW = mydict, posV, negV, totalposwords, totalnegwords\n",
    "#     print(mydict)\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(train_set, train_labels, dev_set):\n",
    "    #Baseline#\n",
    "    # return predicted labels of development set\n",
    "    # print(\"not even started yet\")\n",
    "    smoothing_parameter = laplace\n",
    "    \n",
    "#     start = time.process_time()\n",
    "\n",
    "#     print(\"Going through train set took: \", time.process_time() - start)\n",
    "    mydict, posV, negV, totalposwords, totalnegwords = bagOfWordsNB(train_set, train_labels)\n",
    "#     print(\"mydict\")\n",
    "#     print(mydict)\n",
    "#     print(\"posV\")\n",
    "#     print(posV)\n",
    "#     print(\"negV\")\n",
    "#     print(negV)\n",
    "#     print(\"totalposwords\")\n",
    "#     print(totalposwords)\n",
    "#     print(\"totalnegwords\")\n",
    "#     print(totalnegwords)\n",
    "    \n",
    "    \n",
    "    #come up with the bag of words unigram model\n",
    "    probWordPos = {}\n",
    "    probWordNeg = {}\n",
    "\n",
    "    for x in mydict:\n",
    "        #use laplace smoothing\n",
    "        # count(W) + a / n + a * (V+1)\n",
    "        # n = number of words in our training data\n",
    "        # count(W) = number of times W appeared in training data\n",
    "        # Î± is a tuning constant between 0 and 1 (typically small)\n",
    "        # V = number of word TYPES seen in training data\n",
    "        probWordPos[x] = math.log((mydict[x][0] + smoothing_parameter) / (totalposwords + smoothing_parameter * (posV + 1)))\n",
    "        probWordNeg[x] = math.log((mydict[x][1] + smoothing_parameter) / (totalnegwords + smoothing_parameter * (negV + 1)))\n",
    "#     start = time.process_time()\n",
    "\n",
    "    # dev set\n",
    "    predictions = []\n",
    "    for x in range(len(dev_set)):\n",
    "        chancePos = 0\n",
    "        chanceNeg = 0 \n",
    "        if(Prior):\n",
    "            chancePos += math.log(posPrior)\n",
    "            chanceNeg += math.log(1-posPrior)\n",
    "        for y in range(len(dev_set[x])):\n",
    "            if dev_set[x][y] in mydict:\n",
    "                chancePos += probWordPos[dev_set[x][y]]\n",
    "                chanceNeg += probWordNeg[dev_set[x][y]]\n",
    "            # else:\n",
    "                # chancePos += math.log((smoothing_parameter) / (totalposwords + smoothing_parameter * (posV + 1)))\n",
    "                # chanceNeg += math.log((smoothing_parameter) / (totalnegwords + smoothing_parameter * (negV + 1)))\n",
    "        if(chancePos > chanceNeg):\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "#     print(\"devset time took:\", time.process_time() - start)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuraciesNB(predictedLabels, dev_set, dev_labels):\n",
    "    yhats = predictedLabels\n",
    "    accuracy = np.mean(yhats == dev_labels)\n",
    "    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(yhats))])\n",
    "    precision = tp / np.sum([yhats[i] == 1 for i in range(len(yhats))])\n",
    "    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(yhats))]) + tp)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuraciesSK(predictedLabels):\n",
    "    dev_labels = [1]*200+[0]*200\n",
    "    yhats = predictedLabels\n",
    "    accuracy = np.mean(yhats == dev_labels)\n",
    "    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(yhats))])\n",
    "    precision = tp / np.sum([yhats[i] == 1 for i in range(len(yhats))])\n",
    "    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(yhats))]) + tp)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### scikit pre processing methods ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWordsSK(reviews):\n",
    "    wbag = {}\n",
    "#     stops = stopwords.words('english') + list(string.punctuation)    -- global variable for speed\n",
    "    for review in reviews:\n",
    "        with open(review, 'r') as f:\n",
    "            for line in f:\n",
    "                text = myTokenize(line)\n",
    "                for word in text:\n",
    "                    wbag[word] = wbag.get(word, 0) + 1\n",
    "    return wbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimBags(pWbag, nWbag):\n",
    "    posList = {}\n",
    "    negList = {}\n",
    "#     print(\"prefilter\")\n",
    "#     print(len(pWbag))\n",
    "#     print(len(nWbag))\n",
    "    #force words to only exist in either positive or negative bags\n",
    "    if(Unique):\n",
    "        for key in nWbag.keys():\n",
    "            if key in pWbag.keys():\n",
    "                posFreq = pWbag[key]\n",
    "                negFreq = nWbag[key]\n",
    "                if int(posFreq) >= int(negFreq):\n",
    "                    posList[key] = pWbag[key]\n",
    "                elif int(posFreq) < int(negFreq):\n",
    "                    negList[key] = nWbag[key]\n",
    "            else:\n",
    "                negList[key] = nWbag[key]\n",
    "        for key in pWbag.keys():\n",
    "            if key not in nWbag.keys():\n",
    "                posList[key] = pWbag[key]\n",
    "    else:\n",
    "        posList = pWbag\n",
    "        negList = nWbag\n",
    "#     print(\"first filter\")\n",
    "#     print(len(posList))\n",
    "#     print(len(negList))\n",
    "    #determine the boundary size\n",
    "    max_length=min(len(negList),len(posList))\n",
    "#     print(\"max_length\")\n",
    "#     print(max_length)\n",
    "    #sort the keys of the map into a list, sorting to get most frequently used words\n",
    "    sortedNegList = sorted(negList, key=negList.get, reverse=True)[:max_length]\n",
    "    sortedPosList = sorted(posList, key=posList.get, reverse=True)[:max_length]\n",
    "#     print(\"sorted max filter\")\n",
    "#     print(len(sortedNegList))\n",
    "#     print(len(sortedPosList))\n",
    "    #turn the sorted list into a usable mapping again\n",
    "    new_neg= {k:negList[k] for k in sortedNegList}\n",
    "    new_pos = {k:posList[k] for k in sortedPosList}\n",
    "#     print(\"k filter\")\n",
    "#     print(len(new_pos))\n",
    "#     print(len(new_neg))\n",
    "    return new_pos,new_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTokenize(line):\n",
    "    line = line.strip()\n",
    "    line = line.split(\" \")\n",
    "#     res = [] \n",
    "#     for sub in line:\n",
    "#         res.append(re.sub('\\n', '', sub))\n",
    "#     line = res\n",
    "#     stops = stopwords.words('english') + list(string.punctuation)    -- global variable for speed\n",
    "    if Alpha:\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "#         print(\"Alpha\")\n",
    "#         print(line)\n",
    "    if Stop:\n",
    "        line = [word for word in line if word not in list(set(stops) - set(['not']))]\n",
    "#         print(\"Stop\")\n",
    "#         print(line)\n",
    "    if Stemming:\n",
    "        porter_stemmer = PorterStemmer()\n",
    "        for i in range(len(line)):\n",
    "            line[i] = porter_stemmer.stem(line[i])\n",
    "    if POS:\n",
    "        tagSet = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS', 'RP']\n",
    "        tagged = nltk.pos_tag([i for i in line if i])\n",
    "#         print(\"tagged\")\n",
    "#         print(tagged)\n",
    "#         print(\"senetence before\")\n",
    "#         print(line)\n",
    "        line = [w for w, tag, in zip(line,tagged) if (\"JJ\" in tag) or (\"JJR\" in tag) or (\"JJS\" in tag) or (\"RB\" in tag) or (\"RBR\" in tag) or (\"RBS\" in tag) or (\"RP\" in tag)] #adjective or adverd\n",
    "#         print(\"senetence after\")\n",
    "#         print(line)\n",
    "    if Negation:\n",
    "        line = nltk.sentiment.util.mark_negation(line)\n",
    "#         print(\"Negation\")\n",
    "#         print(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSortedKeyList(bag1,bag2):\n",
    "    keyList = [*bag1] + list(set([*bag2]) - set([*bag1]))\n",
    "    keyList = sorted(keyList)\n",
    "    return keyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skPreprocessing(dataset):\n",
    "    trainPos,trainNeg,testPos,testNeg = getPosNegReviews(dataset)\n",
    "    pWbag = bagOfWordsSK(trainPos)\n",
    "    nWbag = bagOfWordsSK(trainNeg)\n",
    "    pos_keys, neg_keys = trimBags(pWbag, nWbag)\n",
    "    keyList = getSortedKeyList(pWbag,nWbag)\n",
    "    cv = CountVectorizer(input='filename', tokenizer=myTokenize, lowercase=True, vocabulary=keyList)\n",
    "#     print(keyList)\n",
    "    trainFileNames = trainPos + trainNeg\n",
    "    testFileNames = testPos + testNeg\n",
    "    trainSet = cv.fit_transform(trainFileNames)\n",
    "    testSet = cv.fit_transform(testFileNames)\n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(trainSet, testSet):\n",
    "    LRclassifier = LogisticRegression()\n",
    "    labels = [1]*800+[0]*800\n",
    "    LRclassifier.fit(trainSet,labels)\n",
    "    predictions = LRclassifier.predict(testSet)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supportVectorMachine(trainSet, testSet):\n",
    "    SVMclassifier = LinearSVC()\n",
    "    labels = [1]*800+[0]*800\n",
    "    SVMclassifier.fit(trainSet,labels)\n",
    "    predictions = SVMclassifier.predict(testSet)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(trainSet, testSet):\n",
    "    SVMclassifier = DecisionTreeClassifier()\n",
    "    labels = [1]*800+[0]*800\n",
    "    SVMclassifier.fit(trainSet,labels)\n",
    "    predictions = SVMclassifier.predict(testSet)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset):\n",
    "    trainSet, trainLabels, revSet, revLabels = loadDatasetNB(dataset)\n",
    "    trainSetSK, testSetSK = skPreprocessing(dataset)\n",
    "    \n",
    "\n",
    "    predictedLabelsNB = naiveBayes(trainSet, trainLabels, revSet)\n",
    "    predictedLabelsLR = logisticRegression(trainSetSK, testSetSK)\n",
    "    predictedLabelsSVM = supportVectorMachine(trainSetSK, testSetSK)\n",
    "    predictedLabelsDT = decisionTree(trainSetSK,testSetSK)\n",
    "    \n",
    "    accuracyNB, f1NB, precisionNB, recallNB = compute_accuraciesNB(predictedLabelsNB, revSet, revLabels)\n",
    "    accuracyLR, f1LR, precisionLR, recallLR = compute_accuraciesSK(predictedLabelsLR)\n",
    "    accuracySVM, f1SVM, precisionSVM, recallSVM = compute_accuraciesSK(predictedLabelsSVM)\n",
    "    accuracyDT, f1DT, precisionDT, recallDT = compute_accuraciesSK(predictedLabelsDT)\n",
    "    \n",
    "    NBscores = accuracyNB, f1NB, precisionNB, recallNB\n",
    "#     NBscores = [0,0,0,0]\n",
    "    LRscores = accuracyLR, f1LR, precisionLR, recallLR\n",
    "    SVMscores = accuracySVM, f1SVM, precisionSVM, recallSVM\n",
    "    DTscores = accuracyDT, f1DT, precisionDT, recallDT\n",
    "#     print(\"Accuracy:\",accuracy)\n",
    "#     print(\"F1-Score:\",f1)\n",
    "#     print(\"Precision:\",precision)\n",
    "#     print(\"Recall:\",recall)\n",
    "    return NBscores, LRscores, SVMscores, DTscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 1000/1000 [00:00<00:00, 3203.45it/s]\n",
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 1000/1000 [00:00<00:00, 3066.29it/s]\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 - Baseline ----------------------------------------\n",
      "Alpha---\n",
      "False\n",
      "Stop---\n",
      "False\n",
      "Stemming-----\n",
      "False\n",
      "POS-----\n",
      "False\n",
      "Negation---\n",
      "False\n",
      "Unique-----\n",
      "False\n",
      "Prior---\n",
      "False\n",
      "number of runtimes: 1\n",
      "Final results NAIVE BAYES----------------------------------\n",
      "Average Accuracy: 0.735\n",
      "Average F1: 0.7376237623762375\n",
      "Average Precision: 0.7303921568627451\n",
      "Average recall 0.745\n",
      "Final results  LOGISTIC REGRESSION----------------------------------\n",
      "Average Accuracy: 0.8275\n",
      "Average F1: 0.8253164556962025\n",
      "Final results SUPPORT VECTOR MACHINE----------------------------------\n",
      "Average Accuracy: 0.8275\n",
      "Average F1: 0.8261964735516373\n",
      "Final results DECISION TREE----------------------------------\n",
      "Average Accuracy: 0.7025\n",
      "Average F1: 0.7076167076167076\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'allDone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d3dcefa9f72f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;31m#     print(\"STD Recall:\", stdRecall)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m \u001b[0mallDone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'allDone' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #base trial globals\n",
    "    dataset = \"../TermProject/txt_sentoken\"\n",
    "    stops = stopwords.words('english') + list(string.punctuation)\n",
    "    Alpha = False\n",
    "    Stop = False\n",
    "    Stemming = False\n",
    "    POS = False\n",
    "    Negation = False\n",
    "    Unique = False\n",
    "    Prior = False\n",
    "    laplace = 0.034\n",
    "    posPrior = 0.8\n",
    "    \n",
    "    ##Naive bayes\n",
    "    accuracyNB = []\n",
    "    f1NB = []\n",
    "    precisionNB = []\n",
    "    recallNB = []\n",
    "    \n",
    "    #Logistic regression\n",
    "    accuracyLR = []\n",
    "    f1LR = []\n",
    "    precisionLR = []\n",
    "    recallLR = []\n",
    "    \n",
    "    #Support Vector Machine\n",
    "    accuracySVM = []\n",
    "    f1SVM = []\n",
    "    precisionSVM = []\n",
    "    recallSVM = []\n",
    "    \n",
    "    #Decision Tree\n",
    "    accuracyDT = []\n",
    "    f1DT = []\n",
    "    precisionDT = []\n",
    "    recallDT = []\n",
    "    \n",
    "    numberOfRuntimes = 1\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for i in range(numberOfRuntimes):\n",
    "        NBscores, LRscores, SVMscores, DTscores = main(dataset)\n",
    "#         NBscores = main(dataset)\n",
    "        accuracyNB.append(NBscores[0])\n",
    "        f1NB.append(NBscores[1])\n",
    "        precisionNB.append(NBscores[2])\n",
    "        recallNB.append(NBscores[3])\n",
    "\n",
    "        accuracyLR.append(LRscores[0])\n",
    "        f1LR.append(LRscores[1])\n",
    "        precisionLR.append(LRscores[2])\n",
    "        recallLR.append(LRscores[3])\n",
    "\n",
    "        accuracySVM.append(SVMscores[0])\n",
    "        f1SVM.append(SVMscores[1])\n",
    "        precisionSVM.append(SVMscores[2])\n",
    "        recallSVM.append(SVMscores[3])\n",
    "\n",
    "        accuracyDT.append(DTscores[0])\n",
    "        f1DT.append(DTscores[1])\n",
    "        precisionDT.append(DTscores[2])\n",
    "        recallDT.append(DTscores[3])\n",
    "        \n",
    "\n",
    "    \n",
    "    #Printing the Variables of the current trial\n",
    "#     Alpha = False\n",
    "#     Stop = False\n",
    "#     POS = False\n",
    "#     Negation = False\n",
    "#     Unique = False\n",
    "#     Stemming = False\n",
    "#     Prior = False\n",
    "#     laplace = 0.034\n",
    "#     posPrior = 0.8\n",
    "#     numberOfRuntimes = 10\n",
    "    print(\"Trial 1 - Baseline ----------------------------------------\")\n",
    "    print(\"Alpha---\")\n",
    "    print(Alpha)\n",
    "    print(\"Stop---\")\n",
    "    print(Stop)\n",
    "    print(\"Stemming-----\")\n",
    "    print(Stemming)\n",
    "    print(\"POS-----\")\n",
    "    print(POS)\n",
    "    print(\"Negation---\")\n",
    "    print(Negation)\n",
    "\n",
    "    print(\"Unique-----\")\n",
    "    print(Unique)\n",
    "    print(\"Prior---\")\n",
    "    print(Prior)\n",
    "    print(\"number of runtimes:\", numberOfRuntimes)\n",
    "    #RESULTS OF NAIVE BAYES (unigram) \n",
    "    aveAccuracy = np.mean(accuracyNB)\n",
    "    avef1 = np.mean(f1NB)\n",
    "    avePrecision = np.mean(precisionNB)\n",
    "    aveRecall = np.mean(recallNB)\n",
    "    stdAccuracy = np.std(accuracyNB)\n",
    "    stdf1 = np.std(f1NB)\n",
    "    stdPrecision = np.std(precisionNB)\n",
    "    stdRecall = np.std(recallNB)\n",
    "    \n",
    "    \n",
    "    ########   Note:  There are a lot of commented out measurements of performance because I was going to incorporate all of\n",
    "    ####### them into a single visualization intially. However, visualizing all of these variables was too messy,\n",
    "    ####### and so instead I opted for simplying comparing average Accuracies.\n",
    "    ########\n",
    "    ########  Also note, I was prepared to run all feature combinations on all algorithms, but it was taking way too long, and \n",
    "    ######## crashing randomly during long runs. Instead, I opted for reducing the runs to 2 for the late features and also \n",
    "    ######## showing a baseline feature addition approach as mentioned in rubric \n",
    "\n",
    "    print(\"Final results NAIVE BAYES----------------------------------\")\n",
    "#     print(\"Accuracy:\",accuracyNB)\n",
    "#     print(\"F1-Score:\",f1NB)\n",
    "#     print(\"Precision:\",precisionNB)\n",
    "#     print(\"Recall:\",recallNB)\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "#     print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "#     print(\"STD F1:\", stdf1)\n",
    "    print(\"Average Precision:\", avePrecision)\n",
    "#     print(\"STD Precision:\", stdPrecision)\n",
    "    print(\"Average recall\", aveRecall)\n",
    "#     print(\"STD Recall:\", stdRecall)\n",
    "    \n",
    "#     #RESULTS OF LOGISTIC REGRESSION\n",
    "    aveAccuracy = np.mean(accuracyLR)\n",
    "    avef1 = np.mean(f1LR)\n",
    "#     avePrecision = np.mean(precisionLR)\n",
    "#     aveRecall = np.mean(recallLR)\n",
    "#     stdAccuracy = np.std(accuracyLR)\n",
    "#     stdf1 = np.std(f1LR)\n",
    "#     stdPrecision = np.std(precisionLR)\n",
    "#     stdRecall = np.std(recallLR)\n",
    "    print(\"Final results  LOGISTIC REGRESSION----------------------------------\")\n",
    "#     print(\"Accuracy:\",accuracyLR)\n",
    "#     print(\"F1-Score:\",f1LR)\n",
    "#     print(\"Precision:\",precisionLR)\n",
    "#     print(\"Recall:\",recallLR)\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "#     print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "#     print(\"STD F1:\", stdf1)\n",
    "#     print(\"Average Precision:\", avePrecision)\n",
    "#     print(\"STD Precision:\", stdPrecision)\n",
    "#     print(\"Average recall\", aveRecall)\n",
    "#     print(\"STD Recall:\", stdRecall)\n",
    "    \n",
    "#     #RESULTS OF SUPPORT VECTOR MACHINE\n",
    "    aveAccuracy = np.mean(accuracySVM)\n",
    "    avef1 = np.mean(f1SVM)\n",
    "#     avePrecision = np.mean(precisionSVM)\n",
    "#     aveRecall = np.mean(recallSVM)\n",
    "#     stdAccuracy = np.std(accuracySVM)\n",
    "#     stdf1 = np.std(f1SVM)\n",
    "#     stdPrecision = np.std(precisionSVM)\n",
    "#     stdRecall = np.std(recallSVM)\n",
    "    print(\"Final results SUPPORT VECTOR MACHINE----------------------------------\")\n",
    "#     print(\"Accuracy:\",accuracySVM)\n",
    "#     print(\"F1-Score:\",f1SVM)\n",
    "#     print(\"Precision:\",precisionSVM)\n",
    "#     print(\"Recall:\",recallSVM)\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "#     print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "#     print(\"STD F1:\", stdf1)\n",
    "#     print(\"Average Precision:\", avePrecision)\n",
    "#     print(\"STD Precision:\", stdPrecision)\n",
    "#     print(\"Average recall\", aveRecall)\n",
    "#     print(\"STD Recall:\", stdRecall)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#     #RESULTS OF DECISION TREE\n",
    "    aveAccuracy = np.mean(accuracyDT)\n",
    "    avef1 = np.mean(f1DT)\n",
    "#     avePrecision = np.mean(precisionDT)\n",
    "#     aveRecall = np.mean(recallDT)\n",
    "#     stdAccuracy = np.std(accuracyDT)\n",
    "#     stdf1 = np.std(f1DT)\n",
    "#     stdPrecision = np.std(precisionDT)\n",
    "#     stdRecall = np.std(recallDT)\n",
    "    print(\"Final results DECISION TREE----------------------------------\")\n",
    "#     print(\"Accuracy:\",accuracyDT)\n",
    "#     print(\"F1-Score:\",f1DT)\n",
    "#     print(\"Precision:\",precisionDT)\n",
    "#     print(\"Recall:\",recallDT)\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "#     print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "#     print(\"STD F1:\", stdf1)\n",
    "#     print(\"Average Precision:\", avePrecision)\n",
    "#     print(\"STD Precision:\", stdPrecision)\n",
    "#     print(\"Average recall\", aveRecall)\n",
    "#     print(\"STD Recall:\", stdRecall)\n",
    "\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 1 - Baseline ----------------------------------------\n",
    "#     Alpha = False\n",
    "#     Stop = False\n",
    "#     POS = False\n",
    "#     Negation = False\n",
    "#     Unique = False\n",
    "#     Stemming = False\n",
    "#     Prior = False\n",
    "#     laplace = 0.034\n",
    "#     posPrior = 0.8\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.79875\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.8355\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.8265\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.63975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 2 - Baseline + Alpha ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# False\n",
    "# Stemming-----\n",
    "# False\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.79025\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.8355\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.82575\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 3 - Baseline + Alpha + Stop ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# False\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.7862500000000001\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.8404999999999999\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.8342499999999999\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.6275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 3 - Baseline + Alpha + Stop ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# False\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.7969999999999999\n",
    "# Average F1: 0.796478316397207\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.8314999999999999\n",
    "# Average F1: 0.8320190563443252\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.8245000000000001\n",
    "# Average F1: 0.8251299491764266\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.63475\n",
    "# Average F1: 0.6350275636427405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 4 - Baseline + Alpha + Stop + Stemming ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# True\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.79325\n",
    "# Average F1: 0.7903109835488404\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.83825\n",
    "# Average F1: 0.8377428690324334\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.82175\n",
    "# Average F1: 0.8192189591136172\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.6322500000000001\n",
    "# Average F1: 0.6340694553210997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 5 - Baseline ----------------------------------------\n",
    "# Alpha---\n",
    "# False\n",
    "# Stop---\n",
    "# False\n",
    "# Stemming-----\n",
    "# False\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.8082499999999999\n",
    "# Average F1: 0.8070739683677216\n",
    "# Average Precision: 0.8119863442980957\n",
    "# Average recall 0.8025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 6 - Baseline + Alpha ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# False\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.79925\n",
    "# Average F1: 0.796046707\n",
    "# Average Precision: 0.809030569\n",
    "# Average recall 0.784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 7 - Baseline + Alpha + Stop ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# False\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.7895\n",
    "# Average F1: 0.7893473207800615\n",
    "# Average Precision: 0.7900923986942613\n",
    "# Average recall 0.7889999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 8 - Baseline + Alpha + Stop Stemming----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# True\n",
    "# Negation---\n",
    "# False\n",
    "# POS-----\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.784\n",
    "# Average F1: 0.7826437622790621\n",
    "# Average Precision: 0.7888889830524213\n",
    "# Average recall 0.7769999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 9 - Baseline Alpha Stop Stemming POS----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# True\n",
    "# POS-----\n",
    "# True\n",
    "# Negation---\n",
    "# False\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes = 10\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.7475\n",
    "# Average F1: 0.7574037683504797\n",
    "# Average Precision: 0.7297940797940798\n",
    "# Average recall 0.7875000000000001\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.7475\n",
    "# Average F1: 0.7574037683504797\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.7475\n",
    "# Average F1: 0.7574037683504797\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.7475\n",
    "# Average F1: 0.7574037683504797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 10 - Baseline Alpha Stop Stemming POS negation ----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# True\n",
    "# POS-----\n",
    "# True\n",
    "# Negation---\n",
    "# True\n",
    "# Unique-----\n",
    "# False\n",
    "# Prior---\n",
    "# False\n",
    "# number of runtimes: 2\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.74125\n",
    "# Average F1: 0.739082804\n",
    "# Average Precision: 0.744076986\n",
    "# Average recall 0.735\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.76625\n",
    "# Average F1: 0.763604398414525\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.7262500000000001\n",
    "# Average F1: 0.7246730888514753\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.6275\n",
    "# Average F1: 0.6269543464665417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forgot to print 11, which was all -Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 12 - Baseline ALL----------------------------------------\n",
    "# Alpha---\n",
    "# True\n",
    "# Stop---\n",
    "# True\n",
    "# Stemming-----\n",
    "# True\n",
    "# POS-----\n",
    "# True\n",
    "# Negation---\n",
    "# True\n",
    "# Unique-----\n",
    "# True\n",
    "# Prior---\n",
    "# True\n",
    "# number of runtimes: 2\n",
    "# Final results NAIVE BAYES----------------------------------\n",
    "# Average Accuracy: 0.73\n",
    "# Average F1: 0.746473285134897\n",
    "# Average Precision: 0.7035557644110275\n",
    "# Average recall 0.795\n",
    "# Final results  LOGISTIC REGRESSION----------------------------------\n",
    "# Average Accuracy: 0.72625\n",
    "# Average F1: 0.7301123923514816\n",
    "# Final results SUPPORT VECTOR MACHINE----------------------------------\n",
    "# Average Accuracy: 0.71875\n",
    "# Average F1: 0.7219621313058465\n",
    "# Final results DECISION TREE----------------------------------\n",
    "# Average Accuracy: 0.6287499999999999\n",
    "# Average F1: 0.6319513543394141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
