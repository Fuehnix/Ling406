{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import string\n",
    "import glob\n",
    "import numpy as np\n",
    "import nltk.sentiment.util\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.metrics import *\n",
    "\n",
    "\n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReviewNames(posDir, negDir):\n",
    "    positive = glob.glob(posDir)\n",
    "    negative = glob.glob(negDir)\n",
    "#     print(positive)\n",
    "#     print(negative)\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads dataset in a way that will work with scikit\n",
    "def getPosNegReviews(directory):\n",
    "    positive, negative = loadReviewNames(directory + '/pos/*',directory + '/neg/*')\n",
    "    random.shuffle(positive)\n",
    "    boundaryTrain = math.floor(0.8 * len(positive))\n",
    "    trainPos = positive[:boundaryTrain]\n",
    "    random.shuffle(negative)\n",
    "    trainNeg = negative[:boundaryTrain]\n",
    "    \n",
    "    testPos = positive[boundaryTrain:]\n",
    "    testNeg = negative[boundaryTrain:]\n",
    "    return trainPos,trainNeg,testPos,testNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POSTag(data):\n",
    "    for sentence in data:\n",
    "        tagged = nltk.pos_tag(sentence)\n",
    "        print(\"tagged\")\n",
    "        print(tagged)\n",
    "        print(\"senetence before\")\n",
    "        print(sentence)\n",
    "        sentence = [w for w, tag, in zip(sentence,tagged) \n",
    "                 if tag == \"J\" or tag == \"R\"] #adjective or adverd\n",
    "        print(\"sentence after\")\n",
    "        print(sentence)\n",
    "     # create part of speech tag\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDir(name):\n",
    "    # Loads the files in the folder and returns a list of lists of words from the text in each file\n",
    "    if Stemming:\n",
    "        porter_stemmer = PorterStemmer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    data = []\n",
    "    count = 0\n",
    "    for f in tqdm(listdir(name)):\n",
    "        fullname = name+f\n",
    "        text = []\n",
    "        with open(fullname, 'rb') as f:\n",
    "            for line in f:\n",
    "                if Lowercase:\n",
    "                    line = line.decode(errors='ignore').lower()\n",
    "                    text += tokenizer.tokenize(line)\n",
    "                else:\n",
    "                    text += tokenizer.tokenize(line.decode(errors='ignore'))\n",
    "        if Stemming:\n",
    "            for i in range(len(text)):\n",
    "#                 if text[i] in bad_words:\n",
    "#                     continue\n",
    "                text[i] = porter_stemmer.stem(text[i])\n",
    "        data.append(text)\n",
    "        count = count + 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads dataset in a way that will work with my unigram Naive bayes implementation\n",
    "def loadDatasetNB(directory):\n",
    "    positive = loadDir(directory + '/pos/')\n",
    "    negative = loadDir(directory + '/neg/')\n",
    "    print(\"tokenize in load\")\n",
    "    for review in positive:\n",
    "        review = myTokenize(review)\n",
    "    for review in negative:\n",
    "        review = myTokenize(review)\n",
    "        \n",
    "    random.shuffle(positive)\n",
    "    boundaryTrain = math.floor(0.8 * len(positive))\n",
    "    trainPos = positive[:boundaryTrain]\n",
    "    random.shuffle(negative)\n",
    "    trainNeg = negative[:boundaryTrain]\n",
    "    combinedTrain = trainPos + trainNeg\n",
    "    length = len(trainPos) + len(trainNeg)\n",
    "    labelsTrain = len(trainNeg) * [1] + len(trainNeg) * [0]\n",
    "    labelsTrain = np.array(labelsTrain)\n",
    "\n",
    "    testPos = positive[boundaryTrain:]\n",
    "    testNeg = negative[boundaryTrain:]\n",
    "    combinedTest = testPos + testNeg\n",
    "    labelsTest = len(testPos) * [1] + len(testNeg) * [0]\n",
    "    labelsTest = np.array(labelsTest)\n",
    "    return combinedTrain, labelsTrain, combinedTest, labelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for unigram Naive bayes implementation\n",
    "def bagOfWordsNB(train_set, train_labels):\n",
    "    mydict = {}\n",
    "    posV = 0\n",
    "    negV = 0\n",
    "    totalposwords = 0\n",
    "    totalnegwords = 0\n",
    "\n",
    "#   start = time.process_time()\n",
    "\n",
    "    #create bag of words and number of occurences\n",
    "    count = 0\n",
    "    for x in train_set:\n",
    "        rating = train_labels[count]\n",
    "        count += 1\n",
    "        if(rating):\n",
    "            for y in x:\n",
    "                if y not in mydict:\n",
    "                    mydict[y] = [1,0] #default [1 pos, 0 neg]\n",
    "                    posV += 1\n",
    "                    totalposwords += 1\n",
    "                else:\n",
    "                    if mydict[y][0] == 0:\n",
    "                        posV += 1\n",
    "                    mydict[y][0] += 1\n",
    "                    totalposwords += 1\n",
    "        else:\n",
    "            for y in x:\n",
    "                if y not in mydict:\n",
    "                    mydict[y] = [0,1] #default [0 pos, 1 neg]\n",
    "                    negV += 1\n",
    "                    totalnegwords += 1\n",
    "                else:\n",
    "                    if mydict[y][1] == 0:\n",
    "                        negV += 1\n",
    "                    mydict[y][1] += 1\n",
    "                    totalnegwords += 1\n",
    "#     print(\"review count is: \", count)\n",
    "#     print(\"posV\", posV)\n",
    "#     print(\"negV\", negV)\n",
    "#     print(\"total word count is:\", totalposwords + totalnegwords)\n",
    "    BOW = mydict, posV, negV, totalposwords, totalnegwords\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(train_set, train_labels, dev_set):\n",
    "    #Baseline#\n",
    "    # return predicted labels of development set\n",
    "    # print(\"not even started yet\")\n",
    "    smoothing_parameter = 0.034\n",
    "\n",
    "#     start = time.process_time()\n",
    "\n",
    "#     print(\"Going through train set took: \", time.process_time() - start)\n",
    "    mydict, posV, negV, totalposwords, totalnegwords = bagOfWordsNB(train_set, train_labels)\n",
    "    \n",
    "    \n",
    "    #come up with the bag of words unigram model\n",
    "    probWordPos = {}\n",
    "    probWordNeg = {}\n",
    "\n",
    "    for x in mydict:\n",
    "        #use laplace smoothing\n",
    "        # count(W) + a / n + a * (V+1)\n",
    "        # n = number of words in our training data\n",
    "        # count(W) = number of times W appeared in training data\n",
    "        # Î± is a tuning constant between 0 and 1 (typically small)\n",
    "        # V = number of word TYPES seen in training data\n",
    "        if(Smoothing):\n",
    "            probWordPos[x] = math.log((mydict[x][0] + smoothing_parameter) / (totalposwords + smoothing_parameter * (posV + 1)))\n",
    "            probWordNeg[x] = math.log((mydict[x][1] + smoothing_parameter) / (totalnegwords + smoothing_parameter * (negV + 1)))\n",
    "        else:\n",
    "            probWordPos[x] = math.log((mydict[x][0]) / (totalposwords))\n",
    "            probWordNeg[x] = math.log((mydict[x][1]) / (totalnegwords))\n",
    "#     start = time.process_time()\n",
    "\n",
    "    # dev set\n",
    "    predictions = []\n",
    "    for x in range(len(dev_set)):\n",
    "        chancePos = 0\n",
    "        chanceNeg = 0 \n",
    "        if(Prior):\n",
    "            chancePos += math.log(posPrior)\n",
    "            chanceNeg += math.log(1-posPrior)\n",
    "        for y in range(len(dev_set[x])):\n",
    "            if dev_set[x][y] in mydict:\n",
    "                chancePos += probWordPos[dev_set[x][y]]\n",
    "                chanceNeg += probWordNeg[dev_set[x][y]]\n",
    "            # else:\n",
    "                # chancePos += math.log((smoothing_parameter) / (totalposwords + smoothing_parameter * (posV + 1)))\n",
    "                # chanceNeg += math.log((smoothing_parameter) / (totalnegwords + smoothing_parameter * (negV + 1)))\n",
    "        if(chancePos > chanceNeg):\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "#     print(\"devset time took:\", time.process_time() - start)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuraciesNB(predictedLabels, dev_set, dev_labels):\n",
    "    yhats = predictedLabels\n",
    "    accuracy = np.mean(yhats == dev_labels)\n",
    "    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(yhats))])\n",
    "    precision = tp / np.sum([yhats[i] == 1 for i in range(len(yhats))])\n",
    "    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(yhats))]) + tp)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuraciesSK(predictedLabels):\n",
    "    dev_labels = [1]*200+[0]*200\n",
    "    yhats = predictedLabels\n",
    "    accuracy = np.mean(yhats == dev_labels)\n",
    "    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(yhats))])\n",
    "    precision = tp / np.sum([yhats[i] == 1 for i in range(len(yhats))])\n",
    "    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(yhats))]) + tp)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### scikit pre processing methods ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWordsSK(reviews):\n",
    "    word_bag = {}\n",
    "    stops = stopwords.words('english') + list(string.punctuation)\n",
    "    for review in reviews:\n",
    "        with open(review, 'r') as f:\n",
    "            line = f.read()\n",
    "            line = line.split(\" \")\n",
    "            if Stop:\n",
    "                line = [word for word in line if word not in set(stops)]\n",
    "            if Alpha:\n",
    "                line = [word for word in line if word.isalpha()]\n",
    "            for word in line:\n",
    "                word_bag[word] = word_bag.get(word, 0) + 1\n",
    "    return word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimBags(pWbag, nWbag):\n",
    "    posList = {}\n",
    "    negList = {}\n",
    "    print(\"prefilter\")\n",
    "    print(len(pWbag))\n",
    "    print(len(nWbag))\n",
    "    #force words to only exist in either positive or negative bags\n",
    "    if(Unique):\n",
    "        for key in nWbag.keys():\n",
    "            if key in pWbag.keys():\n",
    "                posFreq = pWbag[key]\n",
    "                negFreq = nWbag[key]\n",
    "                if int(posFreq) >= int(negFreq):\n",
    "                    posList[key] = pWbag[key]\n",
    "                elif int(posFreq) < int(negFreq):\n",
    "                    negList[key] = nWbag[key]\n",
    "            else:\n",
    "                negList[key] = nWbag[key]\n",
    "        for key in pWbag.keys():\n",
    "            if key not in nWbag.keys():\n",
    "                posList[key] = pWbag[key]\n",
    "    else:\n",
    "        posList = pWbag\n",
    "        negList = nWbag\n",
    "    print(\"first filter\")\n",
    "    print(len(posList))\n",
    "    print(len(negList))\n",
    "    #determine the boundary size\n",
    "    max_length=min(len(negList),len(posList))\n",
    "    print(\"max_length\")\n",
    "    print(max_length)\n",
    "    #sort the keys of the map into a list, sorting to get most frequently used words\n",
    "    sortedNegList = sorted(negList, key=negList.get, reverse=True)[:max_length]\n",
    "    sortedPosList = sorted(posList, key=posList.get, reverse=True)[:max_length]\n",
    "    print(\"sorted max filter\")\n",
    "    print(len(sortedNegList))\n",
    "    print(len(sortedPosList))\n",
    "    #turn the sorted list into a usable mapping again\n",
    "    new_neg= {k:negList[k] for k in sortedNegList}\n",
    "    new_pos = {k:posList[k] for k in sortedPosList}\n",
    "#     print(\"k filter\")\n",
    "#     print(len(new_pos))\n",
    "#     print(len(new_neg))\n",
    "    return new_pos,new_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myTokenize(line, stop=True, negation=True):\n",
    "    line = line.split(\" \")\n",
    "    stops = stopwords.words('english') + list(string.punctuation)\n",
    "    if Alpha:\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        print(\"Alpha\")\n",
    "        print(line)\n",
    "    if Stop:\n",
    "        line = [word for word in line if word not in list(set(stops) - set(['not']))]\n",
    "        print(\"Stop\")\n",
    "        print(line)\n",
    "    if POS:\n",
    "        tagSet = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS', 'RP']\n",
    "        tagged = nltk.pos_tag([i for i in line if i])\n",
    "        print(\"tagged\")\n",
    "        print(tagged)\n",
    "        print(\"senetence before\")\n",
    "        print(line)\n",
    "        line = [w for w, tag, in zip(line,tagged) if (\"JJ\" in tag) or (\"JJR\" in tag) or (\"JJS\" in tag) or (\"RB\" in tag) or (\"RBR\" in tag) or (\"RBS\" in tag) or (\"RP\" in tag)] #adjective or adverd\n",
    "        print(\"senetence after\")\n",
    "        print(line)\n",
    "    if Negation:\n",
    "        line = nltk.sentiment.util.mark_negation(line)\n",
    "        print(\"Negation\")\n",
    "        print(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSortedKeyList(bag1,bag2):\n",
    "    keyList = [*bag1] + list(set([*bag2]) - set([*bag1]))\n",
    "    keyList = sorted(keyList)\n",
    "    return keyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skPreprocessing(dataset):\n",
    "    trainPos,trainNeg,testPos,testNeg = getPosNegReviews(dataset)\n",
    "    pWbag = bagOfWordsSK(trainPos)\n",
    "    nWbag = bagOfWordsSK(trainNeg)\n",
    "    pos_keys, neg_keys = trimBags(pWbag, nWbag)\n",
    "    keyList = getSortedKeyList(pWbag,nWbag)\n",
    "    cv = CountVectorizer(input='filename', tokenizer=myTokenize, lowercase=True, vocabulary=keyList)\n",
    "    trainFileNames = trainPos + trainNeg\n",
    "    testFileNames = testPos + testNeg\n",
    "    trainSet = cv.fit_transform(trainFileNames)\n",
    "    testSet = cv.fit_transform(testFileNames)\n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(trainSet, testSet):\n",
    "    LRclassifier = LogisticRegression()\n",
    "    labels = [1]*800+[0]*800\n",
    "    LRclassifier.fit(trainSet,labels)\n",
    "    predictions = LRclassifier.predict(testSet)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supportVectorMachine(trainSet, testSet):\n",
    "    SVMclassifier = LinearSVC()\n",
    "    labels = [1]*800+[0]*800\n",
    "    SVMclassifier.fit(trainSet,labels)\n",
    "    predictions = SVMclassifier.predict(testSet)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(trainSet, testSet):\n",
    "    SVMclassifier = DecisionTreeClassifier()\n",
    "    labels = [1]*800+[0]*800\n",
    "    SVMclassifier.fit(trainSet,labels)\n",
    "    predictions = SVMclassifier.predict(testSet)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset, stemming, lowerCase,stop, negation, laplace, posPrior):\n",
    "    trainSet, trainLabels, revSet, revLabels = loadDatasetNB(dataset)\n",
    "    trainSetSK, testSetSK = skPreprocessing(dataset)\n",
    "\n",
    "    predictedLabelsNB = naiveBayes(trainSet, trainLabels, revSet)\n",
    "    predictedLabelsLR = logisticRegression(trainSetSK, testSetSK)\n",
    "    predictedLabelsSVM = supportVectorMachine(trainSetSK, testSetSK)\n",
    "    predictedLabelsDT = decisionTree(trainSetSK,testSetSK)\n",
    "    \n",
    "    accuracyNB, f1NB, precisionNB, recallNB = compute_accuraciesNB(predictedLabelsNB, revSet, revLabels)\n",
    "    accuracyLR, f1LR, precisionLR, recallLR = compute_accuraciesSK(predictedLabelsLR)\n",
    "    accuracySVM, f1SVM, precisionSVM, recallSVM = compute_accuraciesSK(predictedLabelsSVM)\n",
    "    accuracyDT, f1DT, precisionDT, recallDT = compute_accuraciesSK(predictedLabelsDT)\n",
    "    \n",
    "    NBscores = accuracyNB, f1NB, precisionNB, recallNB\n",
    "    LRscores = accuracyLR, f1LR, precisionLR, recallLR\n",
    "    SVMscores = accuracySVM, f1SVM, precisionSVM, recallSVM\n",
    "    DTscores = accuracyDT, f1DT, precisionDT, recallDT\n",
    "#     print(\"Accuracy:\",accuracy)\n",
    "#     print(\"F1-Score:\",f1)\n",
    "#     print(\"Precision:\",precision)\n",
    "#     print(\"Recall:\",recall)\n",
    "    return NBscores, LRscores, SVMscores, DTscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\n",
      " 21%|âââââââââââââââââ                                                            | 213/1000 [00:00<00:00, 2114.51it/s]\n",
      " 42%|âââââââââââââââââââââââââââââââââ                                            | 421/1000 [00:00<00:00, 2099.40it/s]\n",
      " 61%|âââââââââââââââââââââââââââââââââââââââââââââââ                              | 608/1000 [00:00<00:00, 2020.08it/s]\n",
      " 80%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ               | 798/1000 [00:00<00:00, 1977.93it/s]\n",
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 1000/1000 [00:00<00:00, 1997.27it/s]\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\n",
      " 23%|ââââââââââââââââââ                                                           | 228/1000 [00:00<00:00, 2263.50it/s]\n",
      " 42%|âââââââââââââââââââââââââââââââââ                                            | 418/1000 [00:00<00:00, 2135.37it/s]\n",
      " 62%|âââââââââââââââââââââââââââââââââââââââââââââââââ                            | 625/1000 [00:00<00:00, 2110.60it/s]\n",
      " 83%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ             | 830/1000 [00:00<00:00, 2087.23it/s]\n",
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 1000/1000 [00:00<00:00, 2063.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize in load\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-329-ac52d9cb284e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mnumberOfRuntimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumberOfRuntimes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mNBscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLRscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVMscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDTscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstemming\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowerCase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlaplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposPrior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0maccuracyNB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNBscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mf1NB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNBscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-328-1e846f948be2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(dataset, stemming, lowerCase, stop, negation, laplace, posPrior)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstemming\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowerCase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlaplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposPrior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDatasetNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrainSetSK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestSetSK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskPreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredictedLabelsNB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-314-cec9b483cd11>\u001b[0m in \u001b[0;36mloadDatasetNB\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenize in load\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyTokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mreview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyTokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-322-fd72a301b4f8>\u001b[0m in \u001b[0;36mmyTokenize\u001b[1;34m(line, stop, negation)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmyTokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mstops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mAlpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = \"../TermProject/txt_sentoken\"\n",
    "    dataset = \"../TermProject/txt_sentoken\"\n",
    "    Stemming = False\n",
    "    Lowercase = True\n",
    "    Stop = True\n",
    "    Alpha = True\n",
    "    Negation = True\n",
    "    POS = True\n",
    "    Unique = True\n",
    "    Smoothing = True\n",
    "    Prior = True\n",
    "    laplace = 0.034\n",
    "    posPrior = 0.8\n",
    "    \n",
    "    ##Naive bayes\n",
    "    accuracyNB = []\n",
    "    f1NB = []\n",
    "    precisionNB = []\n",
    "    recallNB = []\n",
    "    \n",
    "    #Logistic regression\n",
    "    accuracyLR = []\n",
    "    f1LR = []\n",
    "    precisionLR = []\n",
    "    recallLR = []\n",
    "    \n",
    "    #Support Vector Machine\n",
    "    accuracySVM = []\n",
    "    f1SVM = []\n",
    "    precisionSVM = []\n",
    "    recallSVM = []\n",
    "    \n",
    "    #Decision Tree\n",
    "    accuracyDT = []\n",
    "    f1DT = []\n",
    "    precisionDT = []\n",
    "    recallDT = []\n",
    "    \n",
    "    numberOfRuntimes = 3\n",
    "    for i in range(numberOfRuntimes):\n",
    "        NBscores, LRscores, SVMscores, DTscores = main(dataset, stemming, lowerCase,stop, negation, laplace, posPrior)\n",
    "        accuracyNB.append(NBscores[0])\n",
    "        f1NB.append(NBscores[1])\n",
    "        precisionNB.append(NBscores[2])\n",
    "        recallNB.append(NBscores[3])\n",
    "        \n",
    "        accuracyLR.append(LRscores[0])\n",
    "        f1LR.append(LRscores[1])\n",
    "        precisionLR.append(LRscores[2])\n",
    "        recallLR.append(LRscores[3])\n",
    "        \n",
    "        accuracySVM.append(SVMscores[0])\n",
    "        f1SVM.append(SVMscores[1])\n",
    "        precisionSVM.append(SVMscores[2])\n",
    "        recallSVM.append(SVMscores[3])\n",
    "        \n",
    "        accuracyDT.append(DTscores[0])\n",
    "        f1DT.append(DTscores[1])\n",
    "        precisionDT.append(DTscores[2])\n",
    "        recallDT.append(DTscores[3])\n",
    "        \n",
    "#         print(\"RUN NUMBER \" + str(i+1) + \" ---------------\")\n",
    "#         print(\"Accuracy:\",curaccuracy)\n",
    "#         print(\"F1-Score:\",curf1)\n",
    "#         print(\"Precision:\",curprecision)\n",
    "#         print(\"Recall:\",currecall)\n",
    "\n",
    "    #RESULTS OF NAIVE BAYES (unigram) \n",
    "    aveAccuracy = np.mean(accuracyNB)\n",
    "    avef1 = np.mean(f1NB)\n",
    "    avePrecision = np.mean(precisionNB)\n",
    "    aveRecall = np.mean(recallNB)\n",
    "    stdAccuracy = np.std(accuracyNB)\n",
    "    stdf1 = np.std(f1NB)\n",
    "    stdPrecision = np.std(precisionNB)\n",
    "    stdRecall = np.std(recallNB)\n",
    "    print(\"Final results NAIVE BAYES----------------------------------\")\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "    print(\"Average Precision:\", avePrecision)\n",
    "    print(\"Average recall\", aveRecall)\n",
    "    print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"STD F1:\", stdf1)\n",
    "    print(\"STD Precision:\", stdPrecision)\n",
    "    print(\"STD Recall:\", stdRecall)\n",
    "    \n",
    "    #RESULTS OF LOGISTIC REGRESSION\n",
    "    aveAccuracy = np.mean(accuracyLR)\n",
    "    avef1 = np.mean(f1LR)\n",
    "    avePrecision = np.mean(precisionLR)\n",
    "    aveRecall = np.mean(recallLR)\n",
    "    stdAccuracy = np.std(accuracyLR)\n",
    "    stdf1 = np.std(f1LR)\n",
    "    stdPrecision = np.std(precisionLR)\n",
    "    stdRecall = np.std(recallLR)\n",
    "    print(\"Final results  LOGISTIC REGRESSION----------------------------------\")\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "    print(\"Average Precision:\", avePrecision)\n",
    "    print(\"Average recall\", aveRecall)\n",
    "    print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"STD F1:\", stdf1)\n",
    "    print(\"STD Precision:\", stdPrecision)\n",
    "    print(\"STD Recall:\", stdRecall)\n",
    "    \n",
    "    #RESULTS OF SUPPORT VECTOR MACHINE\n",
    "    aveAccuracy = np.mean(accuracySVM)\n",
    "    avef1 = np.mean(f1SVM)\n",
    "    avePrecision = np.mean(precisionSVM)\n",
    "    aveRecall = np.mean(recallSVM)\n",
    "    stdAccuracy = np.std(accuracySVM)\n",
    "    stdf1 = np.std(f1SVM)\n",
    "    stdPrecision = np.std(precisionSVM)\n",
    "    stdRecall = np.std(recallSVM)\n",
    "    print(\"Final results SUPPORT VECTOR MACHINE----------------------------------\")\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "    print(\"Average Precision:\", avePrecision)\n",
    "    print(\"Average recall\", aveRecall)\n",
    "    print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"STD F1:\", stdf1)\n",
    "    print(\"STD Precision:\", stdPrecision)\n",
    "    print(\"STD Recall:\", stdRecall)\n",
    "    \n",
    "    #RESULTS OF DECISION TREE\n",
    "    aveAccuracy = np.mean(accuracyDT)\n",
    "    avef1 = np.mean(f1DT)\n",
    "    avePrecision = np.mean(precisionDT)\n",
    "    aveRecall = np.mean(recallDT)\n",
    "    stdAccuracy = np.std(accuracyDT)\n",
    "    stdf1 = np.std(f1DT)\n",
    "    stdPrecision = np.std(precisionDT)\n",
    "    stdRecall = np.std(recallDT)\n",
    "    print(\"Final results DECISION TREE----------------------------------\")\n",
    "    print(\"Average Accuracy:\", aveAccuracy)\n",
    "    print(\"Average F1:\", avef1)\n",
    "    print(\"Average Precision:\", avePrecision)\n",
    "    print(\"Average recall\", aveRecall)\n",
    "    print(\"STD Accuracy:\", stdAccuracy)\n",
    "    print(\"STD F1:\", stdf1)\n",
    "    print(\"STD Precision:\", stdPrecision)\n",
    "    print(\"STD Recall:\", stdRecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
